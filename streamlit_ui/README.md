# üìß Agent Mail Interface (Streamlit)

This directory contains the **Streamlit front-end** for the LangGraph multi-agent system. It provides a user interface to simulate incoming emails, visualize agent reasoning (classification), and review or approve drafted responses.

---

## üèóÔ∏è Architecture

This UI operates as the client in a microservices architecture:

* **Frontend (This App):** Runs on port `8501`. Sends JSON payloads to the agent backend.
* **Backend (Agent):** Hosted via FastAPI, expected to be available at `http://127.0.0.1:4000`.
* **LLM (Cluster):** The Large Language Model typically connected via a tunnel on port `8000`.

---

## ‚úÖ Prerequisites

Before running the application, ensure you have the following installed:

* **Python 3.10+**
* **The `uv` package manager**
* **Required Python libraries:**
    ```bash
    pip install streamlit pandas requests
    ```

---

## üöÄ Installation & Startup

To run the full system, you will need to open **3 separate terminal windows** at the **root** of the project folder.

### Linux / macOS

1.  **Terminal 1 (Infrastructure):**
    Deploy the infrastructure.
    ```bash
    make deploy
    ```

2.  **Terminal 2 (Backend):**
    *Wait for Terminal 1 to finish.* (This may take time as it loads the LLM from Hugging Face to the cluster).
    ```bash
    cd src/multi-agent-system
    uv run uvicorn main:fastapi_app --reload --port 4000
    ```

3.  **Terminal 3 (Frontend):**
    Launch the Streamlit UI.
    ```bash
    streamlit run ./streamlit_ui/app.py
    ```

### Windows

1.  **Terminal 1 (Infrastructure):**
    Deploy the infrastructure.
    ```powershell
    make deploy
    ```

2.  **Terminal 2 (Backend):**
    *Wait for Terminal 1 to finish.* (This may take time as it loads the LLM from Hugging Face to the cluster).
    ```powershell
    cd src\multi-agent-system
    uv run uvicorn main:fastapi_app --reload --port 4000
    ```

3.  **Terminal 3 (Frontend):**
    Launch the Streamlit UI.
    ```powershell
    streamlit run .\streamlit_ui\app.py
    ```

> **Note:** Once Terminal 3 is running, your default browser should automatically open to `http://localhost:8501`.

---

## üìñ Usage Guide

### 1. Incoming Email Simulation
Use this section to trigger the agent.
* **Sender Email:** Simulate who sent the message (e.g., `customer@example.com`).
* **Email Content:** Paste the raw email text you want the agent to process.
* **Send to Agent:** Click this button to dispatch the request to the FastAPI backend.

### 2. Review Response
View the results processed by the agent.
* **Classification:** Displays how the agent categorized the email (e.g., "Complaint", "Billing") along with a confidence score.
* **AI Advice:** If the agent detects a critical issue or requires human attention, an alert or recommendation will appear here.
* **Draft Response:** The proposed reply generated by the LLM. You can edit this text before performing the simulated "send."

---

## üîç Troubleshooting

For more detailed information regarding the backend setup, please refer to the documentation located in `src/multi-agent-system/README.md`.